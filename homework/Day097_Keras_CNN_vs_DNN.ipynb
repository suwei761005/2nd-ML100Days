{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/intelpython3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 首先我們使用一般的 DNN (MLP) 來訓練\n",
    "由於 DNN 只能輸入一維的資料，我們要先將影像進行攤平，若 (50000, 32, 32, 3) 的影像，攤平後會變成 (50000, 32*32*3) = (50000, 3072)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 5s 93us/step - loss: 2.1639 - acc: 0.2466 - val_loss: 1.8197 - val_acc: 0.3513\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.8590 - acc: 0.3265 - val_loss: 1.8009 - val_acc: 0.3321\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7833 - acc: 0.3575 - val_loss: 1.6762 - val_acc: 0.4060\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.7327 - acc: 0.3780 - val_loss: 1.7022 - val_acc: 0.3977\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6959 - acc: 0.3896 - val_loss: 1.6314 - val_acc: 0.4194\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6697 - acc: 0.3993 - val_loss: 1.6231 - val_acc: 0.4264\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 2s 44us/step - loss: 1.6483 - acc: 0.4088 - val_loss: 1.6370 - val_acc: 0.4051\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6299 - acc: 0.4182 - val_loss: 1.5738 - val_acc: 0.4466\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 2s 43us/step - loss: 1.6143 - acc: 0.4241 - val_loss: 1.5522 - val_acc: 0.4561\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 2s 42us/step - loss: 1.6003 - acc: 0.4278 - val_loss: 1.5236 - val_acc: 0.4728\n",
      "Test loss: 1.5236255004882813\n",
      "Test accuracy: 0.4728\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 接下來我們使用 CNN 來訓練神經網路\n",
    "CNN 的原理非常適合處理影像類的資料，就讓我們來看看，同樣的訓練條件，CNN 是否顯著優於 DNN 呢?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7666 - acc: 0.3592 - val_loss: 1.3987 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.3330 - acc: 0.5265 - val_loss: 1.1460 - val_acc: 0.5954\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.1267 - acc: 0.6023 - val_loss: 1.0026 - val_acc: 0.6478\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.9935 - acc: 0.6526 - val_loss: 0.9748 - val_acc: 0.6595\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.8920 - acc: 0.6898 - val_loss: 0.8119 - val_acc: 0.7186\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 0.8237 - acc: 0.7140 - val_loss: 0.7926 - val_acc: 0.7251\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.7667 - acc: 0.7316 - val_loss: 0.7685 - val_acc: 0.7384\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.7274 - acc: 0.7489 - val_loss: 0.9322 - val_acc: 0.6901\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6910 - acc: 0.7588 - val_loss: 0.7872 - val_acc: 0.7317\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s 79us/step - loss: 0.6736 - acc: 0.7655 - val_loss: 0.7365 - val_acc: 0.7479\n",
      "Test loss: 0.7365292016983033\n",
      "Test accuracy: 0.7479\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 同樣運算 10 個 epochs，但 CNN 在 test data 的準確率顯著優於 DNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "1. 請試著調整各個超參數，並說明那些超參數對於結果有明顯的影響?\n",
    "2. CNN 與 DNN 哪個模型的參數數量比較多? 造成參數的數量不同的原因在哪?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 17s 345us/step - loss: 2.0286 - acc: 0.2708 - val_loss: 1.7905 - val_acc: 0.3446\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 1.8606 - acc: 0.3262 - val_loss: 1.9167 - val_acc: 0.3156\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 1.8274 - acc: 0.3420 - val_loss: 1.7550 - val_acc: 0.3796\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.8042 - acc: 0.3514 - val_loss: 1.7341 - val_acc: 0.3852\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.7923 - acc: 0.3599 - val_loss: 1.7251 - val_acc: 0.3839\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 1.7858 - acc: 0.3600 - val_loss: 1.7017 - val_acc: 0.3848\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.7861 - acc: 0.3626 - val_loss: 1.7088 - val_acc: 0.3836\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.7783 - acc: 0.3658 - val_loss: 1.7058 - val_acc: 0.3770\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.7830 - acc: 0.3668 - val_loss: 1.6945 - val_acc: 0.4037\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 16s 324us/step - loss: 1.7744 - acc: 0.3707 - val_loss: 1.6969 - val_acc: 0.3934\n",
      "batch_size: 32\n",
      "Test loss: 1.6968859369277953\n",
      "Test accuracy: 0.3934\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.7323 - acc: 0.3844 - val_loss: 1.7328 - val_acc: 0.3812\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.7188 - acc: 0.3868 - val_loss: 1.6939 - val_acc: 0.3856\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 1.7089 - acc: 0.3898 - val_loss: 2.0668 - val_acc: 0.2899\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.7000 - acc: 0.3963 - val_loss: 1.6458 - val_acc: 0.4048\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.7009 - acc: 0.3945 - val_loss: 1.6466 - val_acc: 0.4074\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.6939 - acc: 0.3959 - val_loss: 1.6581 - val_acc: 0.4180\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.6939 - acc: 0.3977 - val_loss: 1.6416 - val_acc: 0.4261\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.6888 - acc: 0.3985 - val_loss: 1.7570 - val_acc: 0.3684\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.6835 - acc: 0.4019 - val_loss: 1.7113 - val_acc: 0.4076\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.6909 - acc: 0.3998 - val_loss: 1.7278 - val_acc: 0.3589\n",
      "batch_size: 64\n",
      "Test loss: 1.7277594173431396\n",
      "Test accuracy: 0.3589\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.6524 - acc: 0.4108 - val_loss: 1.6069 - val_acc: 0.4395\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6488 - acc: 0.4117 - val_loss: 1.6487 - val_acc: 0.4060\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6395 - acc: 0.4146 - val_loss: 1.6255 - val_acc: 0.4221\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6374 - acc: 0.4142 - val_loss: 1.5866 - val_acc: 0.4316\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.6290 - acc: 0.4186 - val_loss: 1.5834 - val_acc: 0.4391\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6287 - acc: 0.4205 - val_loss: 1.6438 - val_acc: 0.4223\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6274 - acc: 0.4193 - val_loss: 1.5820 - val_acc: 0.4427\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6270 - acc: 0.4189 - val_loss: 1.5834 - val_acc: 0.4456\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6201 - acc: 0.4247 - val_loss: 1.6366 - val_acc: 0.4169\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.6237 - acc: 0.4165 - val_loss: 1.6106 - val_acc: 0.4357\n",
      "batch_size: 128\n",
      "Test loss: 1.6106153871536255\n",
      "Test accuracy: 0.4357\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6013 - acc: 0.4277 - val_loss: 1.7014 - val_acc: 0.3889\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5920 - acc: 0.4301 - val_loss: 1.6733 - val_acc: 0.4046\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5950 - acc: 0.4306 - val_loss: 1.5900 - val_acc: 0.4317\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5903 - acc: 0.4316 - val_loss: 1.5547 - val_acc: 0.4526\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5858 - acc: 0.4320 - val_loss: 1.6128 - val_acc: 0.4188\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5864 - acc: 0.4309 - val_loss: 1.5492 - val_acc: 0.4490\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5876 - acc: 0.4308 - val_loss: 1.5781 - val_acc: 0.4349\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5834 - acc: 0.4332 - val_loss: 1.6068 - val_acc: 0.4292\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 4s 80us/step - loss: 1.5836 - acc: 0.4312 - val_loss: 1.6463 - val_acc: 0.4049\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5859 - acc: 0.4327 - val_loss: 1.5918 - val_acc: 0.4378\n",
      "batch_size: 256\n",
      "Test loss: 1.5918311016082765\n",
      "Test accuracy: 0.4378\n"
     ]
    }
   ],
   "source": [
    "#DNN 比較batch size 最佳256\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os\n",
    "batch_size = [32,64,128,256] # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for i in iter(batch_size):\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=i,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('batch_size:',i)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 5s 92us/step - loss: 2.4735 - acc: 0.2264 - val_loss: 2.1293 - val_acc: 0.2315\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.9135 - acc: 0.3087 - val_loss: 2.0106 - val_acc: 0.2947\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.8339 - acc: 0.3404 - val_loss: 1.7450 - val_acc: 0.3642\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.7781 - acc: 0.3605 - val_loss: 1.8032 - val_acc: 0.3612\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7371 - acc: 0.3781 - val_loss: 1.6803 - val_acc: 0.3951\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.7079 - acc: 0.3902 - val_loss: 1.6921 - val_acc: 0.3867\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6733 - acc: 0.4031 - val_loss: 1.5793 - val_acc: 0.4441\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6524 - acc: 0.4091 - val_loss: 1.6653 - val_acc: 0.4090\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6338 - acc: 0.4149 - val_loss: 1.6090 - val_acc: 0.4376\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.6125 - acc: 0.4227 - val_loss: 1.5614 - val_acc: 0.4419\n",
      "epochs: 10\n",
      "Test loss: 1.5613770809173584\n",
      "Test accuracy: 0.4419\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5972 - acc: 0.4272 - val_loss: 1.5708 - val_acc: 0.4472\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5789 - acc: 0.4351 - val_loss: 1.5924 - val_acc: 0.4308\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5622 - acc: 0.4426 - val_loss: 1.6400 - val_acc: 0.4174\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5530 - acc: 0.4453 - val_loss: 1.5766 - val_acc: 0.4315\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5440 - acc: 0.4475 - val_loss: 1.5779 - val_acc: 0.4421\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5287 - acc: 0.4544 - val_loss: 1.4884 - val_acc: 0.4735\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5227 - acc: 0.4557 - val_loss: 1.5754 - val_acc: 0.4463\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5080 - acc: 0.4628 - val_loss: 1.5388 - val_acc: 0.4559\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5050 - acc: 0.4646 - val_loss: 1.4966 - val_acc: 0.4699\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4961 - acc: 0.4665 - val_loss: 1.5012 - val_acc: 0.4579\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4867 - acc: 0.4697 - val_loss: 1.4617 - val_acc: 0.4815\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4753 - acc: 0.4749 - val_loss: 1.4619 - val_acc: 0.4821\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4726 - acc: 0.4751 - val_loss: 1.5044 - val_acc: 0.4732\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4617 - acc: 0.4763 - val_loss: 1.4574 - val_acc: 0.4775\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4573 - acc: 0.4794 - val_loss: 1.5222 - val_acc: 0.4636\n",
      "epochs: 15\n",
      "Test loss: 1.5222053846359254\n",
      "Test accuracy: 0.4636\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4546 - acc: 0.4788 - val_loss: 1.5060 - val_acc: 0.4673\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4478 - acc: 0.4840 - val_loss: 1.5044 - val_acc: 0.4626\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4363 - acc: 0.4885 - val_loss: 1.5148 - val_acc: 0.4644\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.4372 - acc: 0.4864 - val_loss: 1.4957 - val_acc: 0.4684\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4318 - acc: 0.4867 - val_loss: 1.4326 - val_acc: 0.4919\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4233 - acc: 0.4934 - val_loss: 1.4850 - val_acc: 0.4649\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 4s 85us/step - loss: 1.4229 - acc: 0.4933 - val_loss: 1.4463 - val_acc: 0.4872\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4150 - acc: 0.4969 - val_loss: 1.5162 - val_acc: 0.4573\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4084 - acc: 0.4948 - val_loss: 1.4373 - val_acc: 0.4896\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4073 - acc: 0.4965 - val_loss: 1.4729 - val_acc: 0.4742\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4019 - acc: 0.5034 - val_loss: 1.5890 - val_acc: 0.4326\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3955 - acc: 0.5029 - val_loss: 1.4692 - val_acc: 0.4620\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3912 - acc: 0.5022 - val_loss: 1.4959 - val_acc: 0.4701\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3863 - acc: 0.5033 - val_loss: 1.4159 - val_acc: 0.5029\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3874 - acc: 0.5050 - val_loss: 1.4777 - val_acc: 0.4787\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3834 - acc: 0.5079 - val_loss: 1.4721 - val_acc: 0.4768\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3802 - acc: 0.5050 - val_loss: 1.4752 - val_acc: 0.4914\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.3817 - acc: 0.5058 - val_loss: 1.4465 - val_acc: 0.4774\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3764 - acc: 0.5083 - val_loss: 1.5020 - val_acc: 0.4573\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3702 - acc: 0.5086 - val_loss: 1.4360 - val_acc: 0.5101\n",
      "epochs: 20\n",
      "Test loss: 1.4360403186798096\n",
      "Test accuracy: 0.5101\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3668 - acc: 0.5142 - val_loss: 1.4498 - val_acc: 0.4869\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3660 - acc: 0.5128 - val_loss: 1.4771 - val_acc: 0.4725\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3567 - acc: 0.5130 - val_loss: 1.4437 - val_acc: 0.4797\n",
      "Epoch 4/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3585 - acc: 0.5150 - val_loss: 1.4715 - val_acc: 0.4768\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3582 - acc: 0.5159 - val_loss: 1.3999 - val_acc: 0.5052\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3546 - acc: 0.5208 - val_loss: 1.4410 - val_acc: 0.4835\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 4s 86us/step - loss: 1.3501 - acc: 0.5182 - val_loss: 1.4511 - val_acc: 0.4922\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3490 - acc: 0.5183 - val_loss: 1.4105 - val_acc: 0.5018\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3480 - acc: 0.5208 - val_loss: 1.4679 - val_acc: 0.4784\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3404 - acc: 0.5213 - val_loss: 1.4311 - val_acc: 0.4994\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3372 - acc: 0.5249 - val_loss: 1.4114 - val_acc: 0.5079\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3316 - acc: 0.5220 - val_loss: 1.5382 - val_acc: 0.4605\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3403 - acc: 0.5230 - val_loss: 1.4263 - val_acc: 0.4875\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.3317 - acc: 0.5266 - val_loss: 1.4335 - val_acc: 0.4993\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3337 - acc: 0.5250 - val_loss: 1.4100 - val_acc: 0.4952\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3302 - acc: 0.5255 - val_loss: 1.4042 - val_acc: 0.4986\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3175 - acc: 0.5284 - val_loss: 1.5632 - val_acc: 0.4492\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3244 - acc: 0.5296 - val_loss: 1.4685 - val_acc: 0.4755\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3195 - acc: 0.5290 - val_loss: 1.4379 - val_acc: 0.4910\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3211 - acc: 0.5306 - val_loss: 1.4597 - val_acc: 0.4880\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3175 - acc: 0.5295 - val_loss: 1.4349 - val_acc: 0.4945\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3165 - acc: 0.5302 - val_loss: 1.5235 - val_acc: 0.4661\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3123 - acc: 0.5350 - val_loss: 1.4964 - val_acc: 0.4758\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.3175 - acc: 0.5302 - val_loss: 1.4569 - val_acc: 0.4748\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.3056 - acc: 0.5344 - val_loss: 1.4093 - val_acc: 0.5001\n",
      "epochs: 25\n",
      "Test loss: 1.4092892852783203\n",
      "Test accuracy: 0.5001\n"
     ]
    }
   ],
   "source": [
    "#DNN 比較epochs 最佳20 20之後就收斂了\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os\n",
    "batch_size = 256 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = [10,15,20,25] # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "for i in iter(epochs):\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=i,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('epochs:',i)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,841,162\n",
      "Trainable params: 1,841,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 2.1301 - acc: 0.2206 - val_loss: 1.9630 - val_acc: 0.3170\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.9565 - acc: 0.3003 - val_loss: 1.8708 - val_acc: 0.3442\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.8847 - acc: 0.3313 - val_loss: 1.8164 - val_acc: 0.3621\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.8403 - acc: 0.3465 - val_loss: 1.7901 - val_acc: 0.3672\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.8027 - acc: 0.3628 - val_loss: 1.7495 - val_acc: 0.3802\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.7772 - acc: 0.3728 - val_loss: 1.7295 - val_acc: 0.3928\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.7489 - acc: 0.3841 - val_loss: 1.7075 - val_acc: 0.3972\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.7290 - acc: 0.3911 - val_loss: 1.7025 - val_acc: 0.4030\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.7081 - acc: 0.3977 - val_loss: 1.6603 - val_acc: 0.4178\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.6898 - acc: 0.4027 - val_loss: 1.6444 - val_acc: 0.4203\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.6732 - acc: 0.4108 - val_loss: 1.6413 - val_acc: 0.4192\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.6569 - acc: 0.4180 - val_loss: 1.6101 - val_acc: 0.4321\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.6460 - acc: 0.4206 - val_loss: 1.5969 - val_acc: 0.4427\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.6307 - acc: 0.4257 - val_loss: 1.5888 - val_acc: 0.4389\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.6202 - acc: 0.4299 - val_loss: 1.5914 - val_acc: 0.4361\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 1.6083 - acc: 0.4353 - val_loss: 1.5818 - val_acc: 0.4468\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 3s 70us/step - loss: 1.5964 - acc: 0.4381 - val_loss: 1.5640 - val_acc: 0.4438\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 3s 69us/step - loss: 1.5843 - acc: 0.4438 - val_loss: 1.5504 - val_acc: 0.4521\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 71us/step - loss: 1.5744 - acc: 0.4465 - val_loss: 1.5468 - val_acc: 0.4515\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 72us/step - loss: 1.5670 - acc: 0.4483 - val_loss: 1.5362 - val_acc: 0.4603\n",
      "OPTIMIZER: <keras.optimizers.SGD object at 0x0000025801F816D8>\n",
      "Test loss: 1.5361865661621095\n",
      "Test accuracy: 0.4603\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 3.1913 - acc: 0.2216 - val_loss: 1.9142 - val_acc: 0.3024\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.9284 - acc: 0.3075 - val_loss: 1.7845 - val_acc: 0.3526\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.8259 - acc: 0.3443 - val_loss: 1.7912 - val_acc: 0.3379334 - a - ETA: 1s\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7594 - acc: 0.3721 - val_loss: 1.6734 - val_acc: 0.4093\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.7091 - acc: 0.3919 - val_loss: 1.6829 - val_acc: 0.3987\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6850 - acc: 0.3975 - val_loss: 1.7555 - val_acc: 0.3750\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.6543 - acc: 0.4104 - val_loss: 1.8531 - val_acc: 0.3372\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.6295 - acc: 0.4210 - val_loss: 1.6485 - val_acc: 0.3886\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.6019 - acc: 0.4286 - val_loss: 1.6043 - val_acc: 0.4311\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.5800 - acc: 0.4372 - val_loss: 1.5428 - val_acc: 0.4409\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 4s 84us/step - loss: 1.5574 - acc: 0.4462 - val_loss: 1.6343 - val_acc: 0.4249\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.5434 - acc: 0.4522 - val_loss: 1.5449 - val_acc: 0.4604\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5216 - acc: 0.4582 - val_loss: 1.6372 - val_acc: 0.4137\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.5099 - acc: 0.4613 - val_loss: 1.5002 - val_acc: 0.4681\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 83us/step - loss: 1.4949 - acc: 0.4673 - val_loss: 1.5320 - val_acc: 0.4550\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4854 - acc: 0.4709 - val_loss: 1.4902 - val_acc: 0.4737\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4708 - acc: 0.4769 - val_loss: 1.4646 - val_acc: 0.4674\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4600 - acc: 0.4834 - val_loss: 1.6235 - val_acc: 0.4411\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 81us/step - loss: 1.4441 - acc: 0.4850 - val_loss: 1.4795 - val_acc: 0.4664\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 82us/step - loss: 1.4393 - acc: 0.4881 - val_loss: 1.4832 - val_acc: 0.4713\n",
      "OPTIMIZER: <keras.optimizers.RMSprop object at 0x0000025801FA23C8>\n",
      "Test loss: 1.483179515838623\n",
      "Test accuracy: 0.4713\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 4s 88us/step - loss: 1.8065 - acc: 0.4022 - val_loss: 1.4741 - val_acc: 0.4755\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3802 - acc: 0.5060 - val_loss: 1.4577 - val_acc: 0.4797\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 4s 76us/step - loss: 1.3391 - acc: 0.5195 - val_loss: 1.4021 - val_acc: 0.5033\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.3169 - acc: 0.5307 - val_loss: 1.3743 - val_acc: 0.5156\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.3035 - acc: 0.5299 - val_loss: 1.3574 - val_acc: 0.5237\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2869 - acc: 0.5392 - val_loss: 1.3681 - val_acc: 0.5246\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2752 - acc: 0.5450 - val_loss: 1.3436 - val_acc: 0.5321\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2667 - acc: 0.5447 - val_loss: 1.3615 - val_acc: 0.5176\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2549 - acc: 0.5494 - val_loss: 1.3497 - val_acc: 0.5289\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2487 - acc: 0.5522 - val_loss: 1.3631 - val_acc: 0.5172\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2437 - acc: 0.5537 - val_loss: 1.3421 - val_acc: 0.5294\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2376 - acc: 0.5562 - val_loss: 1.3474 - val_acc: 0.5335\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2288 - acc: 0.5593 - val_loss: 1.3489 - val_acc: 0.5260\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2229 - acc: 0.5615 - val_loss: 1.3512 - val_acc: 0.5209\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2201 - acc: 0.5636 - val_loss: 1.3259 - val_acc: 0.5341\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2163 - acc: 0.5640 - val_loss: 1.3235 - val_acc: 0.5364\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2017 - acc: 0.5678 - val_loss: 1.3278 - val_acc: 0.5364\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.2054 - acc: 0.5673 - val_loss: 1.3286 - val_acc: 0.5360\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 4s 78us/step - loss: 1.2000 - acc: 0.5706 - val_loss: 1.3054 - val_acc: 0.5444\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 4s 77us/step - loss: 1.1966 - acc: 0.5706 - val_loss: 1.3181 - val_acc: 0.5372\n",
      "OPTIMIZER: <keras.optimizers.Adagrad object at 0x0000025801FA2208>\n",
      "Test loss: 1.3181051725387574\n",
      "Test accuracy: 0.5372\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.3024 - acc: 0.5302 - val_loss: 1.3563 - val_acc: 0.5252\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.3006 - acc: 0.5329 - val_loss: 1.3528 - val_acc: 0.5200\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2965 - acc: 0.5348 - val_loss: 1.3545 - val_acc: 0.5139\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2894 - acc: 0.5391 - val_loss: 1.3613 - val_acc: 0.5227\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2784 - acc: 0.5414 - val_loss: 1.3470 - val_acc: 0.5217\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2786 - acc: 0.5421 - val_loss: 1.3487 - val_acc: 0.5229\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2700 - acc: 0.5448 - val_loss: 1.3723 - val_acc: 0.5170\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2626 - acc: 0.5469 - val_loss: 1.3723 - val_acc: 0.5126\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2573 - acc: 0.5463 - val_loss: 1.3349 - val_acc: 0.5281\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2485 - acc: 0.5493 - val_loss: 1.3381 - val_acc: 0.5255\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2479 - acc: 0.5515 - val_loss: 1.3388 - val_acc: 0.5222\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2259 - acc: 0.5597 - val_loss: 1.3341 - val_acc: 0.5250\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2301 - acc: 0.5611 - val_loss: 1.3561 - val_acc: 0.5140\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2218 - acc: 0.5605 - val_loss: 1.3297 - val_acc: 0.5270\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2180 - acc: 0.5636 - val_loss: 1.3489 - val_acc: 0.5236\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 5s 96us/step - loss: 1.2094 - acc: 0.5648 - val_loss: 1.3569 - val_acc: 0.5207\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.2032 - acc: 0.5665 - val_loss: 1.3417 - val_acc: 0.5306\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 5s 94us/step - loss: 1.2031 - acc: 0.5679 - val_loss: 1.3508 - val_acc: 0.5213\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1915 - acc: 0.5698 - val_loss: 1.3531 - val_acc: 0.5249\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 5s 95us/step - loss: 1.1903 - acc: 0.5703 - val_loss: 1.3339 - val_acc: 0.5308\n",
      "OPTIMIZER: <keras.optimizers.Adam object at 0x0000025801FA2BA8>\n",
      "Test loss: 1.333917646217346\n",
      "Test accuracy: 0.5308\n"
     ]
    }
   ],
   "source": [
    "#DNN 比較OPTIMIZER 最佳Adagrad \n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam, Adagrad, SGD\n",
    "import os\n",
    "batch_size = 256 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 20 # 訓練的 epochs 數量\n",
    "OPTIMIZER = [SGD(), RMSprop(), Adagrad(), Adam()]\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "# 將資料攤平成一維資料\n",
    "x_train = x_train.reshape(50000, 3072) \n",
    "x_test = x_test.reshape(10000, 3072)\n",
    "\n",
    "# 將資料變為 float32 並標準化\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(3072,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "for i in iter(OPTIMIZER):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=i,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test))\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('OPTIMIZER:',str(i))\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 78s 2ms/step - loss: 1.7681 - acc: 0.3606 - val_loss: 1.3666 - val_acc: 0.5170\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 1.3338 - acc: 0.5282 - val_loss: 1.2170 - val_acc: 0.5758\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 1.1268 - acc: 0.6024 - val_loss: 1.2437 - val_acc: 0.5850\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.9852 - acc: 0.6531 - val_loss: 0.9052 - val_acc: 0.6823\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.8942 - acc: 0.6864 - val_loss: 0.8231 - val_acc: 0.7162\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.8235 - acc: 0.7138 - val_loss: 0.8273 - val_acc: 0.7121\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 0.7701 - acc: 0.7339 - val_loss: 0.7362 - val_acc: 0.7468\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.7260 - acc: 0.7492 - val_loss: 0.7396 - val_acc: 0.7463\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.6928 - acc: 0.7607 - val_loss: 0.7470 - val_acc: 0.7429\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 77s 2ms/step - loss: 0.6733 - acc: 0.7663 - val_loss: 0.6774 - val_acc: 0.7695\n",
      "Test loss: 0.6773562954425811\n",
      "Test accuracy: 0.7695\n"
     ]
    }
   ],
   "source": [
    "#CNN\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "import os\n",
    "batch_size = 128 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 10 # 訓練的 epochs 數量\n",
    "\n",
    "# 讀取資料並檢視\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# 對 label 進行 one-hot encoding (y_trian 原本是純數字)\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN會比DNN的參數少 是因為捲曲神經會經由filter之後去計算出特徵圖而特徵圖有可能會縮小,\n",
    "#再經由池化層去取得平均值或最大值來萃取出較有用的特徵縮小參數"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
